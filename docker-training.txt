
performance and security
https://docs.docker.com/get-started/
docker pull ImageName
//container got it's minimume requier os/kernel inside

docker-compose  -f testdocker.yaml up -d
docker run -d  -p 3230:3130 --name=dockertest  testdocker:1.0 
docker ps -f name=dockertest
docker exec -it 80a4a99f8bf4 sh
docker exec -it mysql bash
curl 127.0.0.1:4130

should set tag version otherwise it will be set to latest
docker build --tag testdocker:1.0 .
create pod: kubectl run testpod --image=testdocker:1.0

kubernetes:
docker desktop , minikube , kind , ...
cluster , node , ...
kubectl get all
kubectl port-forward testpod 5000:3130 // kubectl port-forward pod/[pod-name] 8080:80 //8080 externalport 80 is internal
kubectl port-forward deployment/[deployment-name] 8080:80 
kubectl port-forward service/[servie-name] 8080:80 

services is single point of one or more pods // pods ip addresses will be changed if pod is destroy and create a new one , so we can't rely on ip address
name in the service gets a DNS entry //eg. Frontend pod access backend pod using backend:port

kubectl apply -f testpod.yaml //create apply
deployment>service>replicaset>pod>container
pm2 start app.js -i max

kubectl apply -f testdepl.yaml
kubectl delete deployments  test-depl
zero downtime , terminiting old version and starting new one

kubectl scale deployment [depl-name] replicas=3
kubectl scale -f [yaml-file] --replicas=3 //same as mention in yaml file
autoscale by defining resources and limits

by using services we can connect to pod by service name (pod names and ip can be changed by deleting deployment and nodes)
service loadbalance between pods
serive types:
cluesterip:expose the service to cluster internal IP //default
nodeport:expose  the service to node port static ip
loadbalancer: provsion external ip to act as load balancer for the service
externalName:Maps a service to dns name

kubectl apply -f testsvc.yaml

kubectl describe pod testpod
kubectl exec -it testpod sh
kubectl exec [pod-name] -it sh
apk add curl
curl -s http://podIP:port // or serviceIP or servicename


kubectl logs testpod

kubectl get [pod-name] -o yaml
kubectl get [pod-name] description

docker build --tag  momtaz/auth:1-alpine .
kubectl apply -f auth-mongo-depl.yaml
kubectl apply -f auth-depl.yaml
kubectl apply -f rabbitmq.yaml
docker build --tag  momtaz/order:1-alpine .
kubectl apply -f order-mongo-depl.yaml
kubectl apply -f order-depl.yaml
docker build --tag  momtaz/product:1-alpine .
kubectl apply -f product-mongo-depl.yaml
kubectl apply -f product-depl.yaml
kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.5.1/deploy/static/provider/cloud/deploy.yaml
kubectl wait --namespace ingress-nginx  --for=condition=ready pod   --selector=app.kubernetes.io/component=controller   --timeout=120s
kubectl get pods -nsale
adding sale.com to C:\Windows\System32\drivers\etc
kubectl port-forward --namespace=ingress-nginx service/ingress-nginx-controller 8090:80

create ingress svc
https://kubernetes.github.io/ingress-nginx/deploy/
kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.5.1/deploy/static/provider/cloud/deploy.yaml
kubctl get ing -nsale
kubectl rollout restart deployment NAME
kubectl port-forward --namespace=ingress-nginx service/ingress-nginx-controller 8080:80

skaffold.dev/docs/install

https://kubernetes.io/docs/tasks/access-application-cluster/web-ui-dashboard/
kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v2.7.0/aio/deploy/recommended.yaml
kubectl apply -f dashboard-adminuser.yaml
kubectl apply -f ClusterRoleBinding.yaml
kubectl -n kubernetes-dashboard create token admin-user
kubectl proxy //give a token
Â http://localhost:8001/api/v1/namespaces/kubernetes-dashboard/services/https:kubernetes-dashboard:/proxy/.


docker run -- generate container from the image  
docker run -e MYSQL_ROOT_PASSWORD=12345 -d -p 3308:3306  --name=mysql8 mysql:latest
docker run --link some_database:db -p 8080:8080 adminer
docker run -p 27018:27017 -d -e MONGO_INITDB_ROOT_USERNAME=admin -e MONGO_INITDB_ROOT_PASSWORD=12345 --name mongodb --net mongo-network mongo //the last parameter is image name
docker run -d -p 8081:8081 -e ME_CONFIG_MONGODB_ADMINUSERNAME=admin -e ME_CONFIG_MONGODB_ADMINPASSWORD=12345 -e ME_CONFIG_MONGODB_SERVER=mongodb --net mongo-network --name mongo-express mongo-express //the last parameter is image name and in ME_CONFIG_MONGODB_SERVER we specify mongodb container name

docker start
docker stop
docker ps //list of containers
docker images
docker network create mongo-network
docker network ls
docker tag 4c60c47ec5e4 nodever18:1.0
docker logs ConatainerId
docker exec -it c35296fda438 bash

docker in liara cloud

docker build -t docker-app-test:1-alpine .  //uses dockerfile

//in yml file we dont need to specify the network and docker composer make both container in the same network
docker-compose -f node-app-a.yaml up -d
docker-compose -f node-app-a.yaml down 


jenkins push docker container in docker-repository


docker exec -it iddd /bin/bash or  /bin/sh //exit to exit the shell

env //cmd shows env variables

volumes is used for data persistence 
services:
  web:
    build: ./web
...
    volumes:
      - ./web/:/acc
      - nodemodules:/acc/node_modules/ , name volumes
      - mongo-data:/data/db
    deploy:
      replicas: 2  , A replicated service is a Docker Swarm service that has a specified number of replicas running. These replicas consist of multiple instances of the specified Docker container. In our case, each replica will be a unique Redis instance

volumes:
  nodemodules:
  mongo-data:
    driver: local


Docker is used for building and running multiple transferable environments of the technology stack.
Jenkins is an automated software testing tool for your app.
Kubernetes is a system for automating deployment, scaling, and management. In short, the entire orchestration of containerized applications.


docker run --network docker-training_default --link docker-training-mongodb-1:db -p 8090:8080  --name myadminer  adminer